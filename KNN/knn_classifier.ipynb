{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "zAeYzzHc7P_A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris =datasets.load_iris()\n",
        "X, y =iris.data, iris.target\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fzKz_CA8THu",
        "outputId": "7a70268b-d5e2-4550-a052-e603fceb457b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "QGpBNzQY7Sog"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class my_KNN:\n",
        "\n",
        "  def distance(self,x1,x2):\n",
        "    return np.sqrt(np.sum((x1-x2)**2))\n",
        "\n",
        "  def __init__(self,k=3):\n",
        "    self.k=k\n",
        "\n",
        "  # since knn is a lazy learner it only takes in the data during training\n",
        "  def fit(self,X ,y):\n",
        "    self.X=X\n",
        "    self.y=y\n",
        "\n",
        "  def predict(self,X):\n",
        "    y_predict = [self.predict_new(j) for j in X]\n",
        "    return np.array(y_predict)\n",
        "\n",
        "  def predict_new(self,x):\n",
        "\n",
        "    # Compute distances between x and all examples in the training set\n",
        "    distances = [self.distance(x,x_train) for x_train in self.X]\n",
        "\n",
        "    # Sort by distance and return indices of the first k neighbors\n",
        "    k_nearest = np.argsort(distances)[:self.k]\n",
        "\n",
        "    # Extract the labels of the k nearest neighbor training samples\n",
        "    k_nearest_labels = [self.y[i] for i in k_nearest]\n",
        "\n",
        "    majority_element = Counter(k_nearest_labels).most_common(1)\n",
        "    return majority_element[0][0]\n",
        ""
      ],
      "metadata": {
        "id": "8mrnxb1C7Srv"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "pF94wYmZ7Sux"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 4\n",
        "classifier = my_KNN(k=k)\n",
        "classifier.fit(X_train, y_train)\n",
        "predictions = classifier.predict(X_test)\n",
        "print(\"KNN classification accuracy\", accuracy(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZQQYdxI7Sxp",
        "outputId": "a40a2946-fede-4fc2-d2b7-fb5655de20fb"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN classification accuracy 1.0\n"
          ]
        }
      ]
    }
  ]
}